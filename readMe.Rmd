Commute:  Live in Baltimore, Work at the NIH
========================================================

Looks like my commute to the NIH is more consistent than the ride home to Baltimore, and more fuel efficient too.  On the x-axis, 1 is Monday and 5 is Friday.  On the y-axis, duration in minutes.

```{r fig.width=7, fig.height=6, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
require(RCurl)
KEY <- "1laWhxQ7ugFs1b3nyhDdjp8-DAN9ZK0J3Zn86cM0BhH8"
url <- paste(
    "https://docs.google.com/spreadsheets/d/",KEY,"/export?format=csv&id=",KEY,
    sep="")
myCsv <- getURL(url,.opts=list(ssl.verifypeer=FALSE))
test <- read.csv(textConnection(myCsv))
head(test)
test[1:10,1:5]
commute<-as.data.frame(test[test$destination %in% c("Baltimore","NIH"),])
##commute[commute==""] <- NA
commute$destination<-factor(commute$destination, levels=rev(c("Baltimore","NIH")))
## grab complete cases
commute <- commute[complete.cases(commute[,c("mpg","duration","destination","day")]),]
summary(commute$destination)
## calculate actual data-breaks:
n_rec<-nrow(commute)
## real-data max, min and then put real data spots at (near)quantiles:
breaks_mpg     <- sort(commute$mpg)[c(1, round(n_rec*.25), round(n_rec*.75), n_rec)]
breaks_duration<- sort(commute$duration)[c(1, round(n_rec*.2), round(n_rec*.4), round(n_rec*.6), round(n_rec*.8), n_rec)]
## real-data max, min and then equally divide up space between:
equal_spaced_read_data_labels<-function(data,nlabels){
  mn<-min(data,na.rm=TRUE)
  mx<-max(data,na.rm=TRUE)
  rg<-mx-mn
  sp<-rg/(nlabels-1)
  sq<-seq(mn,mx,by=sp)
  i<-1
  nearest<-rep(NA,nlabels-2)
  for(v in sq[c(-1,-length(sq))]){
    dists<-(data-v)^2
    mn.d<-min(dists,na.rm=TRUE)
    nearest[i]<- data[dists %in% mn.d][1]
    i<-i+1
    }
  c(mn,nearest,mx)
}
breaks_mpg<-equal_spaced_read_data_labels(commute$mpg,4)
breaks_duration<-equal_spaced_read_data_labels(commute$mpg,6)
library(ggplot2)
ggplot(data=commute, aes(x=day, y=duration, size=mpg, color=destination))+
  geom_point(alpha=.5,position = position_jitter(w = 0.1, h = 0))+ 
  scale_y_continuous(breaks=breaks_duration)+ ## explicitly put min/max for y axis 
  facet_grid(.~destination)+scale_size_continuous(range = c(3,10))
```

Another look at fuel efficiency:


```{r fig.width=7, fig.height=6, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
ggplot(data=commute, aes(x=mpg,   y=duration, color=destination))+
  geom_point(alpha=.8,size=5)+ 
  scale_y_continuous(breaks=breaks_duration)+ ## explicitly put min/max for y axis 
  scale_x_continuous(breaks=breaks_mpg)+ ## explicitly put min/max 
  coord_cartesian(xlim=c(range(commute$mpg, na.rm=TRUE)[1]*.95,range(commute$mpg, na.rm=TRUE)[2]*1.05))+ 
  ## give some space so numbers don't mash between facets
  facet_grid(.~destination)
```

Without facetting:

```{r fig.width=7, fig.height=6, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
ggplot(data=commute, aes(x=mpg,   y=duration, color=destination))+
  scale_y_continuous(breaks=breaks_duration)+ ## explicitly put min/max for y axis 
  scale_x_continuous(breaks=breaks_mpg)+ ## explicitly put min/max 
  geom_point(alpha=.8,size=5)
```

Stray Observations:
 
 _The Slow Burn_ was a success (8/20/2014)!  I kept it 55 MPH the whole way and broke the 45 MPG barrier with 48.7 MPG clocking in at 53 minutes (obviously took more time, but there might be wiggle room because there was a wreck late on 495).  Next goal is 50 MPG at under an hour.


Check out the .Rmd file to see code on how to read spreadsheets from Google Drive into R!  Many thanks to [Andrie de Vries and David Smith.](http://blog.revolutionanalytics.com/2014/06/reading-data-from-the-new-version-of-google-spreadsheets.html
)